


from sklearn.datasets import fetch_20newsgroups


ntrain = fetch_20newsgroups(subset='train')





print(ntrain.DESCR)





ntrain.data[:5]





ntrain.target.shape


ntrain.target[:10]


[ntrain.target_names[i] for i in ntrain.target[:10]]





cats = ['sci.space', 'comp.graphics']





ntrain = fetch_20newsgroups(subset='train', categories=cats)
ntest = fetch_20newsgroups(subset='test',categories=cats)


print(ntrain.data[0])





ntrain.target_names


ntrain.target.shape


ntrain.target[:10]


ntest.target.shape





import pandas as pd
import numpy as np

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer





corpus = ["The cat slept and then meowed.", 
          "The tiger slept and then roared.", 
          "The boy ran home and then the boy laughed."]

vectorizer = CountVectorizer()

X = vectorizer.fit_transform(corpus)





vectorizer.get_feature_names_out()


pd.DataFrame(X.toarray(), 
             columns=vectorizer.get_feature_names_out())


# as to compare against our corpus:
corpus





vectorizer = TfidfVectorizer()

X_tfidf = vectorizer.fit_transform(corpus)


pd.DataFrame(X_tfidf.toarray(), 
             columns=vectorizer.get_feature_names_out())





x_bow = pd.DataFrame(X.toarray(), 
             columns=vectorizer.get_feature_names_out())


x_bow


# Getting the term frequencies in each of the three documents
(x_bow.T / x_bow.T.sum(axis=0)).T


# Getting the number of documents in which each word occurs
(x_bow > 0).sum(axis=0)


tf = (x_bow.T / x_bow.T.sum(axis=0)).T

# the +1 at the end is so that even words that occur across all docs
# still have a non-zero TFIDF
# the +1 in numerator and +1 in denominator are conveniences to
# handle the otherwise division by 0 for words that have 0 counts
idf = np.log((1+3) / (1+(x_bow > 0).sum(axis=0))) + 1

tf * idf





tfidf = tf * idf
tfidf = (tfidf.T / np.sqrt((tfidf.T * tfidf.T).sum(axis=0))).T
tfidf


np.dot(tfidf.loc[0], tfidf.loc[1])





vectorizer = TfidfVectorizer()
vectors_train = vectorizer.fit_transform(ntrain.data)
vectors_test = vectorizer.transform(ntest.data)


import pandas as pd


df = pd.DataFrame(vectors_train.toarray(),
                  columns=vectorizer.get_feature_names_out())


df





df[['earth','graphics','image','nasa','algorithms','astronomy']]


from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics


clf = MultinomialNB()
clf.fit(vectors_train, ntrain.target)


pred = clf.predict(vectors_test)


from sklearn.metrics import classification_report


metrics.accuracy_score(ntest.target, pred)


print(classification_report(ntest.target, pred))








vectorizer.get_feature_names_out()





clf.feature_log_prob_


clf.feature_log_prob_.shape





def show_top10(classifier, vectorizer, categories):
    feature_names = vectorizer.get_feature_names_out()
    for i,category in enumerate(categories):
        top10 = np.argsort(-classifier.feature_log_prob_[i])[:10]
        print('%s:' % (category))
        for j in top10:
            print("%s: %.2f" % (feature_names[j], classifier.feature_log_prob_[i][j]))
        print('\n')


show_top10(clf, vectorizer, ntrain.target_names)





ntrain = fetch_20newsgroups(subset='train',categories=cats,remove=('headers','footers','quotes'))
ntest = fetch_20newsgroups(subset='test',categories=cats,remove=('headers','footers','quotes'))


vectors = vectorizer.fit_transform(ntrain.data)
vectors_test = vectorizer.transform(ntest.data)


clf = MultinomialNB()
clf.fit(vectors, ntrain.target)
pred = clf.predict(vectors_test)


print(classification_report(ntest.target, pred))





show_top10(clf, vectorizer, ntrain.target_names)





vectorizer = TfidfVectorizer(stop_words='english', max_df=0.5, min_df=2)


vectors = vectorizer.fit_transform(ntrain.data)
vectors_test = vectorizer.transform(ntest.data)


clf = MultinomialNB()
clf.fit(vectors, ntrain.target)
pred = clf.predict(vectors_test)


print(classification_report(ntest.target, pred))





show_top10(clf, vectorizer, ntrain.target_names)








mypost = '''
I was sitting outside with my cat, looking up at the sky through our telescope, 
when lo and behold, to my little set of eyes I spied an anomalous signal emanating 
from a distant galaxy.  I've scoured my astronomy books and can't find any 
description of what I saw.  Is this a new type of celestial phenomenon? or, 
dare I say it, something extraterrestrial in origin?

Please let me know if you're up for sharing insights on my dataset.
'''





vectorizer.transform([mypost])


vectorizer.transform([mypost]).toarray()





clf.predict(vectorizer.transform([mypost]))


ntrain.target_names[1]





clf.predict_proba(vectorizer.transform([mypost]))
