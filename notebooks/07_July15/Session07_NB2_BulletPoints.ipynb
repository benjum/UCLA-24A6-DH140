{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dbb19159-d973-4eee-8acf-055858042908",
      "metadata": {},
      "source": "# Identify a text's bullet point sentences."
    },
    {
      "cell_type": "markdown",
      "id": "059df828-3b31-416d-9bd9-fbf36ae3599e",
      "metadata": {},
      "source": "Let's say we only want to share the important parts of an article we've read, or that we have lots of journal articles to read but not enough time, so we only want to read the highlights.\n\n* Auto-generate the bullet points\n  * Find most important words\n  * Assign score to sentences based on their words\n  * Output the top-scoring sentences\n\nTo do this we need to know how to:\n* identify word importance\n  * authors tend to repeat important words -> use word frequency\n* assign score to sentences\n  * take the words it contains and sum their \"importances\"\n* output top scorers\n  * rank the sentences"
    },
    {
      "cell_type": "markdown",
      "id": "001d9883-5842-4678-932c-0358ea23f5d6",
      "metadata": {},
      "source": "## Retrieve an interesting article"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea5d10c-f529-4df0-a7ed-2f655e675fa4",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "import requests\nfrom bs4 import BeautifulSoup"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f3c53a-f3f4-4d92-9108-6e5b7ad457d4",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "url = 'https://tedunderwood.com/2015/06/04/seven-ways-humanists-are-using-computers-to-understand-text/'\nresponse = requests.get(url)\ndocument = response.text"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e0f2ac-6d51-4f96-866b-186592e781d4",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "document = BeautifulSoup(response.text, \"html.parser\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b64e3760-8f61-4327-b167-0b1acc97c7e3",
      "metadata": {
        "tags": [],
        "trusted": false
      },
      "outputs": [],
      "source": "humtext = document.find('div', attrs={'class':'entry-content'}).text"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f95d1a-a097-43bd-99be-e9dbf52b2daa",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "for i in ['\\n','[',']','’','”','“']:\n    humtext = humtext.replace(i,' ')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e826b6e4-6ef8-4edc-841d-fc29ce1540fb",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "trusted": false
      },
      "outputs": [],
      "source": "print(humtext)"
    },
    {
      "cell_type": "markdown",
      "id": "5c17911d-d1a0-4d11-acd3-aaa64c271e36",
      "metadata": {},
      "source": "## Process text"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc70bf1b-55a2-4aab-92c0-1a07e8eb885d",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "from nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "712e2e55-1257-44a8-bc18-03bd21babb0d",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "sentences = sent_tokenize(humtext)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d472dd18-f91e-4358-a818-37e6fe397c0d",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "trusted": false
      },
      "outputs": [],
      "source": "sentences"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87694ee0-dac1-401c-bd22-0d33fde63747",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "words = word_tokenize(humtext.lower())"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62d3ab4-6366-4dec-9264-78e0154075e3",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "trusted": false
      },
      "outputs": [],
      "source": "words"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db48ba93-524e-4362-9d9e-fdbbbc25d464",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "myStopWords = list(punctuation) + stopwords.words('english')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9998f0d-6e66-4346-b579-59c8217a1e0c",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "wordsNoStopWords = [w for w in words if w not in myStopWords]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "162cf5cd-5b59-439e-87af-2426a611fb8d",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "trusted": false
      },
      "outputs": [],
      "source": "wordsNoStopWords"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7f66294-5d90-4551-b1a4-deeb6d511b32",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "from nltk.probability import FreqDist"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff914e7-9239-499f-892b-a27dfcff60ca",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "freq = FreqDist(wordsNoStopWords)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b6c7449-4c3f-403a-b658-3b3c30d84c70",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "freq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b6894f",
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "outputs": [],
      "source": "freq.most_common(10)"
    },
    {
      "cell_type": "markdown",
      "id": "c4dd874c",
      "metadata": {},
      "source": "## Slight detour:  visualization"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7955acac",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\nimport pandas as pd\nfrom wordcloud import WordCloud"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f01895",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "# make two lists,\n# one of the words and one of the wordcounts\n\ncommonwords = []\ncommonwords_freq = []\n\nfor i in freq.most_common(10):\n  commonwords.append(i[0])\n  commonwords_freq.append(i[1])\n\n# make a horizontal bar plot\nplt.barh(commonwords, commonwords_freq)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60eca031",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "textNoStopWords = ' '.join(wordsNoStopWords)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63c7b867",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "wordcloud = WordCloud().generate(textNoStopWords)\nplt.imshow(wordcloud)\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c0f619",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "wordcloud = WordCloud(width=800, \n                      height=400, \n                      background_color='white').generate(textNoStopWords)\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "8ab346d0",
      "metadata": {},
      "source": "The Pandas way:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644a8ea0",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "freq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "727a30e7",
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "outputs": [],
      "source": "freq.keys()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36cb4629",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "df_wordrank = pd.DataFrame({'words':freq.keys(),'counts':freq.values()})"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8068b3",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "df_wordrank.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ea3f15b",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "# This is NOT the best plot to make.\n# Why?\n\ndf_wordrank.sort_values(by='counts', ascending=False).plot(kind='barh')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1283a612",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "# two options for better viewing\n\ndf_wordrank.sort_values(by='counts', ascending=False)[:10].plot(x='words',y='counts',kind='barh')\n# df_wordrank.sort_values(by='counts')[-10:].plot(x='words',y='counts',kind='barh')"
    },
    {
      "cell_type": "markdown",
      "id": "4051fa3c",
      "metadata": {},
      "source": "## Ranking sentence \"importance\""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c32d1910-d1bd-4e94-8895-8f52931b45bb",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "for i in sorted(freq, key=freq.get, reverse=True)[:10]:\n    print(i,freq[i])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "408b15f0-6328-48d6-9155-3befdff48087",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "trusted": false
      },
      "outputs": [],
      "source": "ranking = {}\n\nfor sentence in sentences:\n    ranking[sentence] = 0\n    for word in word_tokenize(sentence.lower()):\n        if word in freq:\n            ranking[sentence] += freq[word]\n            \nranking"
    },
    {
      "cell_type": "markdown",
      "id": "fff7e6b1",
      "metadata": {},
      "source": "We can do this in many ways, but let's go the Pandas way."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8836d64a",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "sentrank = pd.DataFrame({'sentence':ranking.keys(),'rank':ranking.values()})"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49388cc6",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "sentrank.sort_values(by='rank',ascending=False)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c01362",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "sentrank = sentrank.sort_values(by='rank',ascending=False).reset_index()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbe590c",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "sentrank.iloc[:5]"
    },
    {
      "cell_type": "markdown",
      "id": "f06d5629",
      "metadata": {},
      "source": "If we want a meaningful summary, we probably want to print them in the same order as they occur in the text.\n\nThe above gives us the top 5 sentences, and we can sort them by the \"index\" column to get them back into the order they occurred in the article:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e9a3a8d",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "sentrank.iloc[:5].sort_values(by='index')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aff62de",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "df_top5 = sentrank.iloc[:5].sort_values(by='index')\n\nfor i,row in df_top5.iterrows():\n  print(row['sentence'])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bdb641",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": "# when we iterate over a dataframe like this\n# the loop variables are the index and the row\n# (and here the index is \"out-of-order\" numerically speaking)\n\ndf_top5 = sentrank.iloc[:5].sort_values(by='index')\n\nfor i,row in df_top5.iterrows():\n  print(i)\n  print(row['sentence'])"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}